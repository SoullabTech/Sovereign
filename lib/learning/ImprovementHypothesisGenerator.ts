// lib/learning/ImprovementHypothesisGenerator.ts
// MAIA Self-Improvement Loop: Observe â†’ Hypothesize â†’ Test â†’ Propose â†’ Human-Sign
//
// Core principle: "MAIA proposes; Mentors approve; Production is human-signed."
// See docs/GOVERNANCE_MENTOR_COVENANT.md for full governance rules.

import { query } from '../db/postgres';
import MisattunementTrackingService from './misattunementTrackingService';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export type HypothesisType =
  | 'prompt_modification'      // Change to system prompts
  | 'skill_parameter'          // Tune skill thresholds/weights
  | 'gating_threshold'         // Claude consultation triggers
  | 'response_constraint'      // Length, tone, format rules
  | 'new_skill'                // Propose new capability
  | 'skill_deprecation';       // Phase out underperforming skill

export type HypothesisPriority = 'critical' | 'high' | 'medium' | 'low';

export type HypothesisStatus =
  | 'proposed'     // Generated by MAIA, awaiting review
  | 'approved'     // Mentor approved, ready for testing
  | 'testing'      // Active A/B test in staging
  | 'validated'    // Test passed, awaiting production deploy
  | 'deployed'     // In production (human-signed)
  | 'rejected'     // Mentor rejected
  | 'failed';      // Test failed

export interface ImprovementHypothesis {
  id?: string;
  type: HypothesisType;
  priority: HypothesisPriority;
  status: HypothesisStatus;
  trigger: {
    source: 'loop_d_rupture' | 'loop_a_feedback' | 'loop_c_comparison' | 'loop_b_gold' | 'cross_loop';
    signalId?: string;
    pattern: string;
    occurrences: number;
    timespan: string;
  };
  modification: {
    target: string;           // e.g., 'AIN_RESPONSE_LENGTH_CONSTRAINT'
    currentValue?: string;
    proposedValue: string;
    rationale: string;
  };
  expectedOutcome: {
    metric: string;           // e.g., 'attunement_score', 'repair_rate'
    currentBaseline?: number;
    expectedImprovement: string;
    measurementPlan: string;
  };
  testConfig?: {
    variant: string;
    sampleSize: number;
    duration: string;
    successCriteria: string;
  };
  results?: {
    sampleSize: number;
    baselineMetric: number;
    testMetric: number;
    improvement: number;
    statisticalSignificance: boolean;
    notes: string;
  };
  deployedBy?: string;       // Mentor who signed for production
  createdAt?: Date;
  updatedAt?: Date;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MISATTUNEMENT â†’ PROMPT TEMPLATES
// Maps rupture categories to specific prompt modifications
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const MISATTUNEMENT_TO_PROMPT_TEMPLATES: Record<string, {
  promptKey: string;
  addConstraint: string;
  rationale: string;
}> = {
  'too-verbose': {
    promptKey: 'AIN_RESPONSE_LENGTH_CONSTRAINT',
    addConstraint: 'Keep responses under 3 sentences unless user explicitly asks for more detail.',
    rationale: 'Multiple users reported feeling overwhelmed by response length.'
  },
  'too-clinical': {
    promptKey: 'AIN_WARMTH_ENHANCEMENT',
    addConstraint: 'Start responses with acknowledgment of feeling before offering perspective.',
    rationale: 'Users reported responses felt cold or detached during emotional moments.'
  },
  'unsolicited-advice': {
    promptKey: 'AIN_CONSENT_GATE',
    addConstraint: 'Ask "Would you like my perspective?" before offering advice or reframing.',
    rationale: 'Users reported feeling lectured when they wanted to be heard.'
  },
  'spiritual-bypassing': {
    promptKey: 'AIN_GROUNDEDNESS_CHECK',
    addConstraint: 'When user expresses pain, acknowledge the difficulty before any meaning-making.',
    rationale: 'Premature meaning-making invalidated user\'s present experience.'
  },
  'pacing-too-fast': {
    promptKey: 'AIN_PACING_AWARENESS',
    addConstraint: 'Match user\'s energy and pace. If they use short messages, respond concisely.',
    rationale: 'Users felt rushed or overwhelmed when MAIA moved faster than their processing.'
  },
  'missed-emotional-cue': {
    promptKey: 'AIN_EMOTIONAL_ATTUNEMENT',
    addConstraint: 'When detecting emotional undertones, name them gently before proceeding.',
    rationale: 'Users felt unseen when emotional subtext was ignored.'
  },
  'boundary-violation': {
    promptKey: 'AIN_BOUNDARY_RESPECT',
    addConstraint: 'If user says "I don\'t want to talk about X", immediately honor that and shift.',
    rationale: 'Critical consent violation - user boundary was not respected.'
  },
  'dependency-risk': {
    promptKey: 'AIN_AGENCY_PRESERVATION',
    addConstraint: 'Regularly reflect user\'s own wisdom back to them. Ask "What do you sense?"',
    rationale: 'User showed signs of over-reliance on MAIA rather than self-trust.'
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// IMPROVEMENT HYPOTHESIS GENERATOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class ImprovementHypothesisGenerator {

  /**
   * MAIN ENTRY POINT
   * Called during dreamtime processing to generate improvement hypotheses
   * from observed patterns across all learning loops.
   */
  async generateHypotheses(): Promise<ImprovementHypothesis[]> {
    const hypotheses: ImprovementHypothesis[] = [];

    console.log('ğŸ§  [Hypothesis Generator] Starting hypothesis generation...');

    // 1. From Loop D: Rupture patterns
    const ruptureHypotheses = await this.generateFromRupturePatterns();
    hypotheses.push(...ruptureHypotheses);

    // 2. From Loop A: Feedback patterns (low attunement clusters)
    const feedbackHypotheses = await this.generateFromFeedbackPatterns();
    hypotheses.push(...feedbackHypotheses);

    // 3. From Loop C: Engine comparison insights
    const comparisonHypotheses = await this.generateFromEngineComparisons();
    hypotheses.push(...comparisonHypotheses);

    // 4. Cross-loop correlations
    const crossLoopHypotheses = await this.generateFromCrossLoopPatterns();
    hypotheses.push(...crossLoopHypotheses);

    // Store all hypotheses
    for (const hypothesis of hypotheses) {
      await this.storeHypothesis(hypothesis);
    }

    console.log(`ğŸ§  [Hypothesis Generator] Generated ${hypotheses.length} hypotheses`);
    return hypotheses;
  }

  /**
   * FROM LOOP D: Rupture/Misattunement Patterns
   * Maps recurring misattunement categories to prompt modifications.
   */
  private async generateFromRupturePatterns(): Promise<ImprovementHypothesis[]> {
    const hypotheses: ImprovementHypothesis[] = [];

    try {
      // Get recent rupture analysis
      const analysis = await MisattunementTrackingService.getRuptureAnalysis(7);

      for (const pattern of analysis.topPatterns) {
        // Only generate hypothesis if pattern occurs 3+ times
        if (pattern.occurrences < 3) continue;

        const template = MISATTUNEMENT_TO_PROMPT_TEMPLATES[pattern.category];
        if (!template) {
          // Unknown category - flag for human review
          hypotheses.push({
            type: 'prompt_modification',
            priority: pattern.occurrences >= 5 ? 'high' : 'medium',
            status: 'proposed',
            trigger: {
              source: 'loop_d_rupture',
              pattern: pattern.category,
              occurrences: pattern.occurrences,
              timespan: '7 days'
            },
            modification: {
              target: 'UNKNOWN - NEEDS HUMAN DESIGN',
              proposedValue: `Address pattern: ${pattern.category}`,
              rationale: `Recurring misattunement (${pattern.occurrences}x in 7 days) without known template.`
            },
            expectedOutcome: {
              metric: 'rupture_rate',
              expectedImprovement: 'Reduce by 30%',
              measurementPlan: 'Track ruptures in this category over next 7 days'
            }
          });
          continue;
        }

        // Generate hypothesis from template
        hypotheses.push({
          type: 'prompt_modification',
          priority: this.calculatePriority(pattern.occurrences, pattern.category),
          status: 'proposed',
          trigger: {
            source: 'loop_d_rupture',
            pattern: pattern.category,
            occurrences: pattern.occurrences,
            timespan: '7 days'
          },
          modification: {
            target: template.promptKey,
            proposedValue: template.addConstraint,
            rationale: template.rationale
          },
          expectedOutcome: {
            metric: 'rupture_rate',
            currentBaseline: pattern.occurrences / 7, // per day
            expectedImprovement: 'Reduce by 40-60%',
            measurementPlan: 'Track ruptures in this category. A/B test with 50% traffic.'
          },
          testConfig: {
            variant: `${template.promptKey}_v1`,
            sampleSize: 100,
            duration: '7 days',
            successCriteria: '30%+ reduction in rupture rate for this category'
          }
        });
      }
    } catch (error) {
      console.error('âŒ Failed to generate rupture hypotheses:', error);
    }

    return hypotheses;
  }

  /**
   * FROM LOOP A: Feedback Patterns
   * Identifies clusters of low attunement scores.
   */
  private async generateFromFeedbackPatterns(): Promise<ImprovementHypothesis[]> {
    const hypotheses: ImprovementHypothesis[] = [];

    try {
      // Query for low-attunement clusters
      const result = await query(`
        SELECT
          felt_state,
          COUNT(*) as count,
          AVG(attunement_score) as avg_attunement
        FROM interaction_feedback
        WHERE created_at > NOW() - INTERVAL '7 days'
          AND attunement_score IS NOT NULL
          AND attunement_score <= 2
        GROUP BY felt_state
        HAVING COUNT(*) >= 3
        ORDER BY count DESC
        LIMIT 5
      `);

      for (const row of result.rows) {
        hypotheses.push({
          type: 'response_constraint',
          priority: row.count >= 5 ? 'high' : 'medium',
          status: 'proposed',
          trigger: {
            source: 'loop_a_feedback',
            pattern: `low_attunement_${row.felt_state || 'unknown'}`,
            occurrences: row.count,
            timespan: '7 days'
          },
          modification: {
            target: 'CONTEXT_SPECIFIC_TUNING',
            proposedValue: `Improve attunement when user felt_state is "${row.felt_state}"`,
            rationale: `${row.count} low attunement scores (avg ${row.avg_attunement?.toFixed(2)}) when user felt "${row.felt_state}"`
          },
          expectedOutcome: {
            metric: 'attunement_score',
            currentBaseline: parseFloat(row.avg_attunement) || 2.0,
            expectedImprovement: 'Increase average attunement to 3.5+',
            measurementPlan: 'Track attunement scores for this felt_state'
          }
        });
      }
    } catch (error) {
      console.error('âŒ Failed to generate feedback hypotheses:', error);
    }

    return hypotheses;
  }

  /**
   * FROM LOOP C: Engine Comparison Insights
   * Identifies cases where shadow engines outperformed primary.
   */
  private async generateFromEngineComparisons(): Promise<ImprovementHypothesis[]> {
    const hypotheses: ImprovementHypothesis[] = [];

    try {
      // Query for shadow engine wins
      const result = await query(`
        SELECT
          sr.engine_name,
          COUNT(*) as wins,
          AVG(sr.ranking_score) as avg_score
        FROM shadow_responses sr
        JOIN engine_comparison_reviews ecr ON sr.id = ecr.shadow_response_id
        WHERE ecr.created_at > NOW() - INTERVAL '14 days'
          AND sr.ranking_score IS NOT NULL
          AND sr.ranking_score > 0.7
        GROUP BY sr.engine_name
        HAVING COUNT(*) >= 3
        ORDER BY wins DESC
        LIMIT 3
      `);

      for (const row of result.rows) {
        hypotheses.push({
          type: 'gating_threshold',
          priority: 'medium',
          status: 'proposed',
          trigger: {
            source: 'loop_c_comparison',
            pattern: `shadow_outperformance_${row.engine_name}`,
            occurrences: row.wins,
            timespan: '14 days'
          },
          modification: {
            target: 'ENGINE_SELECTION_WEIGHTS',
            proposedValue: `Consider increasing weight for ${row.engine_name} in certain contexts`,
            rationale: `${row.engine_name} outperformed primary in ${row.wins} reviewed cases (avg score ${row.avg_score?.toFixed(2)})`
          },
          expectedOutcome: {
            metric: 'response_quality',
            expectedImprovement: 'Improve response quality by leveraging better-performing engines',
            measurementPlan: 'A/B test with adjusted engine weights'
          }
        });
      }
    } catch (error) {
      console.error('âŒ Failed to generate engine comparison hypotheses:', error);
    }

    return hypotheses;
  }

  /**
   * CROSS-LOOP CORRELATIONS
   * Identifies patterns that span multiple learning loops.
   */
  private async generateFromCrossLoopPatterns(): Promise<ImprovementHypothesis[]> {
    const hypotheses: ImprovementHypothesis[] = [];

    try {
      // Example: Correlate Claude consultation with better outcomes
      const result = await query(`
        SELECT
          ct.claude_consultation_used,
          COUNT(*) as total,
          AVG(CASE WHEN ifb.helpfulness_score = 1 THEN 1 ELSE 0 END) as positive_rate
        FROM conversation_turns ct
        LEFT JOIN interaction_feedback ifb ON ct.id = ifb.turn_id
        WHERE ct.created_at > NOW() - INTERVAL '7 days'
          AND ifb.helpfulness_score IS NOT NULL
        GROUP BY ct.claude_consultation_used
      `);

      const withClaude = result.rows.find(r => r.claude_consultation_used);
      const withoutClaude = result.rows.find(r => !r.claude_consultation_used);

      if (withClaude && withoutClaude) {
        const improvement = (withClaude.positive_rate - withoutClaude.positive_rate) * 100;

        if (improvement > 10) {
          hypotheses.push({
            type: 'gating_threshold',
            priority: 'high',
            status: 'proposed',
            trigger: {
              source: 'cross_loop',
              pattern: 'claude_consultation_correlation',
              occurrences: withClaude.total + withoutClaude.total,
              timespan: '7 days'
            },
            modification: {
              target: 'CLAUDE_CONSULTATION_THRESHOLD',
              proposedValue: 'Lower Claude consultation threshold to trigger more often',
              rationale: `Turns with Claude consultation have ${improvement.toFixed(1)}% higher positive feedback rate`
            },
            expectedOutcome: {
              metric: 'positive_feedback_rate',
              currentBaseline: withoutClaude.positive_rate * 100,
              expectedImprovement: `Increase by ${improvement.toFixed(1)}%`,
              measurementPlan: 'Monitor positive feedback rate after threshold adjustment'
            }
          });
        }
      }
    } catch (error) {
      console.error('âŒ Failed to generate cross-loop hypotheses:', error);
    }

    return hypotheses;
  }

  /**
   * STORE HYPOTHESIS
   * Persists a hypothesis to the database for mentor review.
   */
  private async storeHypothesis(hypothesis: ImprovementHypothesis): Promise<string | null> {
    try {
      const result = await query(`
        INSERT INTO improvement_hypotheses (
          type,
          priority,
          status,
          trigger,
          modification,
          expected_outcome,
          test_config
        ) VALUES ($1, $2, $3, $4, $5, $6, $7)
        RETURNING id
      `, [
        hypothesis.type,
        hypothesis.priority,
        hypothesis.status,
        JSON.stringify(hypothesis.trigger),
        JSON.stringify(hypothesis.modification),
        JSON.stringify(hypothesis.expectedOutcome),
        hypothesis.testConfig ? JSON.stringify(hypothesis.testConfig) : null
      ]);

      return result.rows[0]?.id || null;
    } catch (error) {
      console.error('âŒ Failed to store hypothesis:', error);
      return null;
    }
  }

  /**
   * GET PENDING HYPOTHESES
   * Returns hypotheses awaiting mentor review.
   */
  async getPendingHypotheses(): Promise<ImprovementHypothesis[]> {
    try {
      const result = await query(`
        SELECT * FROM improvement_hypotheses
        WHERE status = 'proposed'
        ORDER BY
          CASE priority
            WHEN 'critical' THEN 0
            WHEN 'high' THEN 1
            WHEN 'medium' THEN 2
            WHEN 'low' THEN 3
          END,
          created_at DESC
      `);

      return result.rows.map(row => ({
        id: row.id,
        type: row.type,
        priority: row.priority,
        status: row.status,
        trigger: row.trigger,
        modification: row.modification,
        expectedOutcome: row.expected_outcome,
        testConfig: row.test_config,
        results: row.results,
        deployedBy: row.deployed_by,
        createdAt: row.created_at,
        updatedAt: row.updated_at
      }));
    } catch (error) {
      console.error('âŒ Failed to get pending hypotheses:', error);
      return [];
    }
  }

  /**
   * APPROVE HYPOTHESIS
   * Mentor approves a hypothesis for testing.
   * Returns false if deployment_by is missing (human signature required).
   */
  async approveHypothesis(hypothesisId: string, mentorId: string): Promise<boolean> {
    if (!mentorId) {
      console.error('âŒ Cannot approve hypothesis without mentor signature');
      return false;
    }

    try {
      await query(`
        UPDATE improvement_hypotheses
        SET status = 'approved',
            deployed_by = $2,
            updated_at = NOW()
        WHERE id = $1
      `, [hypothesisId, mentorId]);

      console.log(`âœ… Hypothesis ${hypothesisId} approved by ${mentorId}`);
      return true;
    } catch (error) {
      console.error('âŒ Failed to approve hypothesis:', error);
      return false;
    }
  }

  /**
   * REJECT HYPOTHESIS
   * Mentor rejects a hypothesis with reasoning.
   */
  async rejectHypothesis(hypothesisId: string, mentorId: string, reason: string): Promise<boolean> {
    try {
      await query(`
        UPDATE improvement_hypotheses
        SET status = 'rejected',
            deployed_by = $2,
            results = jsonb_build_object('rejection_reason', $3),
            updated_at = NOW()
        WHERE id = $1
      `, [hypothesisId, mentorId, reason]);

      console.log(`âŒ Hypothesis ${hypothesisId} rejected by ${mentorId}: ${reason}`);
      return true;
    } catch (error) {
      console.error('âŒ Failed to reject hypothesis:', error);
      return false;
    }
  }

  /**
   * RECORD TEST RESULTS
   * Records A/B test results for a hypothesis.
   */
  async recordTestResults(
    hypothesisId: string,
    results: ImprovementHypothesis['results']
  ): Promise<boolean> {
    try {
      const status = results?.statisticalSignificance && results.improvement > 0
        ? 'validated'
        : 'failed';

      await query(`
        UPDATE improvement_hypotheses
        SET status = $2,
            results = $3,
            updated_at = NOW()
        WHERE id = $1
      `, [hypothesisId, status, JSON.stringify(results)]);

      console.log(`ğŸ“Š Hypothesis ${hypothesisId} test completed: ${status}`);
      return true;
    } catch (error) {
      console.error('âŒ Failed to record test results:', error);
      return false;
    }
  }

  /**
   * DEPLOY HYPOTHESIS
   * Marks hypothesis as deployed to production.
   * REQUIRES HUMAN SIGNATURE - this is the "human-signed" gate.
   */
  async deployHypothesis(hypothesisId: string, mentorId: string): Promise<boolean> {
    if (!mentorId) {
      console.error('âŒ GOVERNANCE VIOLATION: Cannot deploy without mentor signature');
      return false;
    }

    try {
      // Verify hypothesis is validated
      const check = await query(`
        SELECT status FROM improvement_hypotheses WHERE id = $1
      `, [hypothesisId]);

      if (check.rows[0]?.status !== 'validated') {
        console.error('âŒ Cannot deploy: hypothesis not validated');
        return false;
      }

      await query(`
        UPDATE improvement_hypotheses
        SET status = 'deployed',
            deployed_by = $2,
            updated_at = NOW()
        WHERE id = $1
      `, [hypothesisId, mentorId]);

      console.log(`ğŸš€ Hypothesis ${hypothesisId} deployed by ${mentorId}`);
      return true;
    } catch (error) {
      console.error('âŒ Failed to deploy hypothesis:', error);
      return false;
    }
  }

  /**
   * CALCULATE PRIORITY
   * Determines priority based on occurrence count and category severity.
   */
  private calculatePriority(count: number, category: string): HypothesisPriority {
    // Critical categories always get elevated priority
    const criticalCategories = ['boundary-violation', 'dependency-risk'];
    if (criticalCategories.includes(category)) {
      return count >= 3 ? 'critical' : 'high';
    }

    if (count >= 10) return 'critical';
    if (count >= 5) return 'high';
    if (count >= 3) return 'medium';
    return 'low';
  }

  /**
   * GET HYPOTHESIS STATS
   * Returns summary statistics for mentor dashboard.
   */
  async getHypothesisStats(): Promise<{
    proposed: number;
    approved: number;
    testing: number;
    validated: number;
    deployed: number;
    rejected: number;
    failed: number;
    byType: Record<HypothesisType, number>;
  }> {
    try {
      const statusResult = await query(`
        SELECT status, COUNT(*) as count
        FROM improvement_hypotheses
        GROUP BY status
      `);

      const typeResult = await query(`
        SELECT type, COUNT(*) as count
        FROM improvement_hypotheses
        GROUP BY type
      `);

      const stats: any = {
        proposed: 0, approved: 0, testing: 0, validated: 0,
        deployed: 0, rejected: 0, failed: 0,
        byType: {}
      };

      for (const row of statusResult.rows) {
        stats[row.status] = parseInt(row.count);
      }

      for (const row of typeResult.rows) {
        stats.byType[row.type as HypothesisType] = parseInt(row.count);
      }

      return stats;
    } catch (error) {
      console.error('âŒ Failed to get hypothesis stats:', error);
      return {
        proposed: 0, approved: 0, testing: 0, validated: 0,
        deployed: 0, rejected: 0, failed: 0,
        byType: {} as Record<HypothesisType, number>
      };
    }
  }
}

export default ImprovementHypothesisGenerator;
