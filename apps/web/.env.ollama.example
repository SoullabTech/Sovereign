# MAIA OPEN SOURCE LLM CONFIGURATION
#
# MAIA's sovereignty: Self-hosted open source models first.
# Claude is optional fallback only.

# ===== OLLAMA CONFIGURATION (PRIMARY) =====
# Self-hosted LLM server for MAIA's independence
OLLAMA_BASE_URL="http://localhost:11434"

# Optional: Enable Claude as fallback (costs money)
ENABLE_CLAUDE_FALLBACK="false"
ANTHROPIC_API_KEY=""

# ===== MODEL CONFIGURATION =====
# MAIA uses DeepSeek V3 for all consciousness levels:
# - Level 1-2: Everyday conversation (DeepSeek V3)
# - Level 3-4: Framework teaching (DeepSeek V3)
# - Level 5: Sacred prosody (DeepSeek V3)

# ===== SETUP INSTRUCTIONS =====
#
# 1. Install Ollama:
#    curl -fsSL https://ollama.com/install.sh | sh
#
# 2. Pull DeepSeek V3:
#    ollama pull deepseek-v3
#
# 3. Verify it's running:
#    ollama list
#
# 4. Start Ollama server (if not already running):
#    ollama serve
#
# 5. Test the API:
#    curl http://localhost:11434/api/tags
#
# MAIA is now fully self-hosted! ðŸŽ‰
