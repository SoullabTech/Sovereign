# IPP Testing Scorecard & Data Collection Form
## Systematic Evaluation Framework for MAIA IPP Integration

---

## Test Session Information

**Test Session ID**: _______________
**Date/Time**: _______________
**Tester Name/ID**: _______________
**Test Environment**: [ ] Local Development [ ] Staging [ ] Other: ___________
**Test Duration**: Start: _______ End: _______ Total: _______
**Browser/Device**: _______________
**Persona Used**: [ ] Sarah (New Parent) [ ] Marcus (Single Father) [ ] Elena (Teen Parent) [ ] Dr. James (Professional) [ ] Other: _______________

---

## Section 1: Conversational Flow Assessment

### A. Trigger Detection (Score 1-5, 5 = Excellent)

| Criteria | Score | Notes |
|----------|--------|-------|
| **Natural Conversation Initiation** | ___/5 | Did MAIA respond appropriately to opening? |
| **Theme Recognition Speed** | ___/5 | How quickly did MAIA identify parenting themes? |
| **Contextual Understanding** | ___/5 | Did MAIA grasp the specific situation/challenges? |
| **Empathy & Tone** | ___/5 | Appropriate emotional response and support? |
| **IPP Offer Timing** | ___/5 | Was the assessment offer well-timed and natural? |

**Trigger Detection Turns**: _____ (How many exchanges before IPP offered?)

**Overall Conversational Flow Score**: ______/25

**Comments**:
```
_________________________________________________
_________________________________________________
_________________________________________________
```

---

### B. Assessment Introduction & Consent (Score 1-5)

| Criteria | Score | Notes |
|----------|--------|-------|
| **Clear Explanation** | ___/5 | Assessment purpose and process well explained? |
| **Privacy Information** | ___/5 | Data handling and confidentiality addressed? |
| **Time Expectations** | ___/5 | Accurate time estimate provided? |
| **Consent Process** | ___/5 | Clear, non-pressured consent obtained? |
| **Opt-out Handling** | ___/5 | Respectful response to hesitation/decline? |

**Overall Consent Process Score**: ______/25

---

## Section 2: Assessment Experience

### A. Question Quality & Flow (Score 1-5)

| Element Category | Clarity | Relevance | Flow | Cultural Sensitivity | Notes |
|------------------|---------|-----------|------|---------------------|-------|
| **Earth Questions** | ___/5 | ___/5 | ___/5 | ___/5 | |
| **Water Questions** | ___/5 | ___/5 | ___/5 | ___/5 | |
| **Fire Questions** | ___/5 | ___/5 | ___/5 | ___/5 | |
| **Air Questions** | ___/5 | ___/5 | ___/5 | ___/5 | |
| **Aether Questions** | ___/5 | ___/5 | ___/5 | ___/5 | |

**Question Count Verification**: _____ questions total (Expected: 40)
**Assessment Completion Time**: _____ minutes

---

### B. User Experience During Assessment (Score 1-5)

| Criteria | Score | Notes |
|----------|--------|-------|
| **Progress Indicators** | ___/5 | Clear sense of progress through assessment? |
| **Response Interface** | ___/5 | Easy to select and modify responses? |
| **Pause/Resume Function** | ___/5 | Could assessment be paused and resumed? |
| **Technical Performance** | ___/5 | No errors, crashes, or delays? |
| **Engagement Level** | ___/5 | Maintained interest throughout? |

**Overall Assessment Experience Score**: ______/25

---

## Section 3: Results & Interpretation

### A. Score Accuracy (Manual Verification)

**Element Scores Received**:
- Earth: _____ (Expected based on responses: _____)
- Water: _____ (Expected based on responses: _____)
- Fire: _____ (Expected based on responses: _____)
- Air: _____ (Expected based on responses: _____)
- Aether: _____ (Expected based on responses: _____)

**Score Accuracy Assessment**:
- [ ] All scores appear accurate
- [ ] Minor discrepancies noted
- [ ] Major scoring errors detected
- [ ] Unable to verify manually

---

### B. Results Presentation Quality (Score 1-5)

| Criteria | Score | Notes |
|----------|--------|-------|
| **Visual Clarity** | ___/5 | Charts, graphs, layout clear and readable? |
| **Interpretation Accuracy** | ___/5 | Written interpretation matches scores? |
| **Personalization Level** | ___/5 | Results feel specific to your responses? |
| **Actionable Insights** | ___/5 | Recommendations practical and helpful? |
| **Language Accessibility** | ___/5 | Non-jargony, understandable language? |

**Dominant Element Identified**: _______________
**Does this match your test responses?** [ ] Yes [ ] Partially [ ] No

**Overall Results Quality Score**: ______/25

---

### C. Recommendations Assessment (Score 1-5)

| Type | Quality | Relevance | Practicality | Notes |
|------|---------|-----------|--------------|-------|
| **Daily Practices** | ___/5 | ___/5 | ___/5 | |
| **Element-Specific Suggestions** | ___/5 | ___/5 | ___/5 | |
| **Resource Recommendations** | ___/5 | ___/5 | ___/5 | |
| **Professional Referrals** | ___/5 | ___/5 | ___/5 | |

---

## Section 4: Professional Interface Testing (If Applicable)

### A. Professional Dashboard (Score 1-5)

| Feature | Functionality | Usability | Data Accuracy | Notes |
|---------|---------------|-----------|---------------|-------|
| **Client List View** | ___/5 | ___/5 | ___/5 | |
| **Assessment History** | ___/5 | ___/5 | ___/5 | |
| **Alert System** | ___/5 | ___/5 | ___/5 | |
| **Analytics Overview** | ___/5 | ___/5 | ___/5 | |

---

### B. Clinical Tools (Score 1-5)

| Tool | Functionality | Clinical Value | Integration | Notes |
|------|---------------|----------------|-------------|-------|
| **Assessment Review** | ___/5 | ___/5 | ___/5 | |
| **Treatment Planning** | ___/5 | ___/5 | ___/5 | |
| **Progress Tracking** | ___/5 | ___/5 | ___/5 | |
| **Documentation** | ___/5 | ___/5 | ___/5 | |

**Overall Professional Interface Score**: ______/60

---

## Section 5: Technical Performance

### A. System Reliability

**Errors Encountered**: [ ] None [ ] Minor [ ] Major [ ] Critical

**Error Details** (if any):
```
_________________________________________________
_________________________________________________
```

**Response Times**:
- Page loads: [ ] Fast (<2s) [ ] Acceptable (2-5s) [ ] Slow (>5s)
- Question transitions: [ ] Smooth [ ] Acceptable [ ] Choppy
- Results generation: [ ] Fast [ ] Acceptable [ ] Slow

### B. Browser Compatibility

**Browser Tested**: _______________
**Issues Noted**: [ ] None [ ] Minor display issues [ ] Major functionality problems

---

## Section 6: Overall Assessment

### A. User Experience Ratings (1-10 scale)

| Aspect | Rating | Comments |
|--------|--------|----------|
| **Ease of Use** | ____/10 | |
| **Engagement Level** | ____/10 | |
| **Perceived Value** | ____/10 | |
| **Trust & Credibility** | ____/10 | |
| **Likelihood to Recommend** | ____/10 | |

### B. Clinical Validity Assessment (For Professional Testers)

| Aspect | Rating (1-5) | Comments |
|--------|---------------|----------|
| **Assessment Questions** | ____/5 | Clinical appropriateness and relevance |
| **Scoring Methodology** | ____/5 | Alignment with IPP principles |
| **Interpretations** | ____/5 | Accuracy and clinical utility |
| **Treatment Recommendations** | ____/5 | Evidence-based and practical |
| **Professional Integration** | ____/5 | Workflow compatibility |

### C. Final Scores Summary

| Category | Score | Possible |
|----------|--------|----------|
| **Conversational Flow** | ______ | /50 |
| **Assessment Experience** | ______ | /65 |
| **Results Quality** | ______ | /45 |
| **Professional Interface** | ______ | /60 |
| **Overall Experience** | ______ | /50 |

**TOTAL SCORE**: ______/270

**Overall Grade**: [ ] A (240-270) [ ] B (210-239) [ ] C (180-209) [ ] D (150-179) [ ] F (<150)

---

## Section 7: Feedback & Recommendations

### A. What Worked Well
```
_________________________________________________
_________________________________________________
_________________________________________________
```

### B. Areas for Improvement
```
_________________________________________________
_________________________________________________
_________________________________________________
```

### C. Critical Issues (Must Fix Before Launch)
```
_________________________________________________
_________________________________________________
_________________________________________________
```

### D. Suggestions for Enhancement
```
_________________________________________________
_________________________________________________
_________________________________________________
```

### E. Would You Use This System?

**As a Parent/Consumer**: [ ] Definitely [ ] Probably [ ] Maybe [ ] Probably Not [ ] Definitely Not

**As a Professional** (if applicable): [ ] Definitely [ ] Probably [ ] Maybe [ ] Probably Not [ ] Definitely Not

**Why or Why Not?**
```
_________________________________________________
_________________________________________________
```

---

## Section 8: Test Scenario Completion Checklist

**Conversational Scenarios Completed**:
- [ ] Basic trigger and flow
- [ ] Hesitant user handling
- [ ] User decline assessment
- [ ] Complex family situation
- [ ] Professional evaluation mode

**Technical Scenarios Tested**:
- [ ] Complete normal flow
- [ ] Mid-assessment pause/resume
- [ ] Browser refresh during assessment
- [ ] Invalid response handling
- [ ] Error recovery testing

**Edge Cases Explored**:
- [ ] Crisis intervention triggers
- [ ] Special needs contexts
- [ ] Cultural adaptation
- [ ] Blended family complexity
- [ ] Professional supervision needs

---

## Section 9: Data Collection Consent

**Test Data Use Authorization**:
- [ ] I consent to anonymized use of this test data for system improvement
- [ ] I consent to sharing aggregated feedback with the development team
- [ ] I consent to follow-up contact for additional testing (optional)

**Tester Contact Information** (optional):
Email: _______________
Preferred contact method: _______________

---

## Section 10: Submission Information

**Completed By**: _______________
**Date Completed**: _______________
**Submission Method**: [ ] Email [ ] File Upload [ ] Direct System Entry
**Additional Files Attached**: [ ] Screenshots [ ] Screen Recording [ ] Error Logs [ ] Other: _______

---

**Testing Team Use Only**:
- Received Date: _______________
- Reviewed By: _______________
- Priority Level: [ ] Low [ ] Medium [ ] High [ ] Critical
- Action Items Created: _______________
- Follow-up Required: [ ] Yes [ ] No

---

*Thank you for your comprehensive testing and feedback! Your input is crucial for improving the IPP integration with MAIA.*